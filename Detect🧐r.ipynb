{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cc4b7b8-5f48-401e-9ef2-89404b4efc2a",
   "metadata": {},
   "source": [
    "### Small summary of the algorithm\n",
    "\n",
    "1. Obtaining the **difference** of two consequtive **frames** to get the part which chenges over time\n",
    "2. Applying the **Gaussian Blur** on this difference to smoothen (and extend a little) the borders of potential cars\n",
    "3. Applying simple **binary thresholding** to binarize the image\n",
    "4. To make to borders a bit more distinguishable, applying **dilation** couple of times\n",
    "5. On the dilated image finding the contours and **bounding boxes** for each of them\n",
    "6. As some of the obtained boxes for moving objects might be decomposed as several boxes isntead of one, next step is **merging the boxes** which might represent the same object, into one using the difference in width and height between centers of boxes\n",
    "7. Once we got the true bounding boxes at each frame, we calculate their trails by **pairwise compare** of bounding boxes using *Intersection over Union* metric. E.g. those, who have  a high IoU are considered as the same object, and we may continue the trail with the color of trail from the previous frame\n",
    "8. **Drawing** the bounding boxes and trails on each of the frames\n",
    "9. **Concatenating** every frame **into** single 60FPS **video**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5b717f-52c0-4b89-9e11-6b70dd78737e",
   "metadata": {},
   "source": [
    "1. Video into frames translation is adapted from:\n",
    "\n",
    "    https://learnopencv.com/reading-and-writing-videos-using-opencv/\n",
    "    \n",
    "2. Idea of taking a differences in frames is taken from:\n",
    "\n",
    "    https://www.analyticsvidhya.com/blog/2020/04/vehicle-detection-opencv-python/\n",
    "    \n",
    "3. Information about opening and closing is taken from:\n",
    "\n",
    "    https://docs.opencv.org/master/d9/d61/tutorial_py_morphological_ops.html\n",
    "    \n",
    "4. Finding the car contours is adapted from:\n",
    "\n",
    "    https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html\n",
    "    \n",
    "5. Merging the frames into video is adapted from:\n",
    "\n",
    "    https://stackoverflow.com/a/44948030\n",
    "    \n",
    "6. Code for finding IoU (Intersection over Union) as adapted from:\n",
    "\n",
    "    https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "    \n",
    "7. Line to draw a point in opencv2 is taken from:\n",
    "\n",
    "    https://stackoverflow.com/a/60546030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49c1201-9fb6-4b94-ad52-ba938043a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f95a84-2624-4258-a126-43cc30fea559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(images):\n",
    "    '''\n",
    "    Showing the images using pyplot  (a helper function)\n",
    "    '''\n",
    "    \n",
    "    # going through each iamge and plotting it\n",
    "    for image in images:\n",
    "        \n",
    "        # detecting the cmap\n",
    "        cmap = 'gray' if len(image.shape) == 2 else None\n",
    "\n",
    "        # setting the size of the figure\n",
    "        plt.figure(figsize = (20, 15))\n",
    "\n",
    "        # showing the image\n",
    "        plt.imshow(image, cmap = cmap)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d78afec2-fe12-439f-9f6b-5c99b3b74846",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingObject:\n",
    "    '''\n",
    "    Class for representing a moving object with its last bounding box,\n",
    "    a random color and limit for a trail (along with trail points)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, coords):\n",
    "        '''\n",
    "        Setting the coorinates of object and assigning a random color with trail limit\n",
    "        '''\n",
    "        \n",
    "        # setting the coordinates\n",
    "        self.coords = coords\n",
    "        \n",
    "        # setting the random RGB color \n",
    "        self.color = tuple(randint(0, 255) for _ in range(3))\n",
    "        \n",
    "        # setting the limit for a tril (in frames)\n",
    "        self.limit = 100\n",
    "        \n",
    "        # initializing a list to hold all the trail points\n",
    "        self.trail = []\n",
    "        \n",
    "        # append a first point\n",
    "        self.draw_point()\n",
    "        \n",
    "    def draw_point(self):\n",
    "        '''\n",
    "        Generate a new trail point and add it to the existing trail\n",
    "        '''\n",
    "        \n",
    "        # generating a center of bounding box\n",
    "        point = ((self.coords[0] + self.coords[2]) // 2, (self.coords[1] + self.coords[3]) // 2)\n",
    "        \n",
    "        # adding it to the trail\n",
    "        self.trail.append(point)\n",
    "        \n",
    "    def iou(self, another_obj):\n",
    "        '''\n",
    "        Calculating Intersection over Union metric of areas between two given moving objects\n",
    "        '''\n",
    "        \n",
    "        # determining coordinates of intersection \n",
    "        xA = max(self.coords[0], another_obj.coords[0])\n",
    "        yA = max(self.coords[1], another_obj.coords[1])\n",
    "        xB = min(self.coords[2], another_obj.coords[2])\n",
    "        yB = min(self.coords[3], another_obj.coords[3])\n",
    "        \n",
    "        # calculating areas of interseciton rectangle \n",
    "        int_area   = max(0, xB - xA) * max(0, yB - yA)\n",
    "        \n",
    "        # calculating the area of two initial boxes and its union part\n",
    "        box1_area  = (self.coords[2] - self.coords[0]) * (self.coords[3] - self.coords[1])\n",
    "        box2_area  = (another_obj.coords[2] - another_obj.coords[0]) * (another_obj.coords[3] - another_obj.coords[1])\n",
    "        union_area = box1_area + box2_area - int_area\n",
    "        \n",
    "        # retuning the ratio of intersection part and union part\n",
    "        return int_area / union_area if union_area else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7886e11-3b5b-4a7b-afef-387e53bdc37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyObjectDetector:\n",
    "    '''\n",
    "    Engine for detecting objects (hopefully cars) from a video in a specified directory\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, video_path):\n",
    "        '''\n",
    "        Opening the video and sampling it into frames\n",
    "        '''\n",
    "        \n",
    "        # open video\n",
    "        video = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        # obtaining colored and grayscale frames from video\n",
    "        self.frames_gray = []\n",
    "        self.frames = []\n",
    "        while video.isOpened():\n",
    "            \n",
    "            # getting the next frame along with end of video flag\n",
    "            flag, frame_bgr = video.read()\n",
    "            \n",
    "            # if we reached the end of stream, stopping\n",
    "            if not flag: break\n",
    "                \n",
    "            # obtaining grayscale version of a particular frame\n",
    "            frame_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # adding both frames to the list\n",
    "            self.frames.append(frame_bgr)\n",
    "            self.frames_gray.append(frame_gray)\n",
    "        \n",
    "        # reseasing the stream video object\n",
    "        video.release()\n",
    "        \n",
    "        # structure holding all the boxes\n",
    "        self.boxes = [] \n",
    "        \n",
    "    def detect_bounding_boxes(self, debug = False):\n",
    "        '''\n",
    "        Function which detects bounding objects for (hopefully) cars\n",
    "        '''\n",
    "        \n",
    "        # going through each frame and polulating the boxes structure\n",
    "        for i in range(1, len(self.frames_gray)):\n",
    "            \n",
    "            # defining the two consequtive frames\n",
    "            previous_frame = self.frames_gray[i - 1].copy()\n",
    "            current_frame  = self.frames_gray[i].copy()\n",
    "            \n",
    "            # taking their difference to detect movement\n",
    "            subtracted = cv2.absdiff(current_frame, previous_frame)\n",
    "            \n",
    "            # applying gaussian blur to smoothen the borders\n",
    "            k = 11\n",
    "            gauss = cv2.GaussianBlur(subtracted, (k, k), 0)\n",
    "            \n",
    "            # cutting out the regions that we're not interested in (upper and lower parts of picture)\n",
    "            gauss[:120, :] = 0\n",
    "            gauss[250:, :] = 0\n",
    "            \n",
    "            # binarizing the differenced using a binary threshold\n",
    "            _, thresh = cv2.threshold(gauss, 25, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            # applying dilating on image to extend the car contours (so it's easier to detect them)\n",
    "            k = 5\n",
    "            dilated = cv2.dilate(thresh, (k, k), iterations = 7)\n",
    "            \n",
    "            # finding the contours of moving objects\n",
    "            contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            # filtering out very small contours (probably noise from sun or objects that only start appearing)\n",
    "            # contours = list(filter(lambda cont: 25 <= cv2.contourArea(cont), contours))\n",
    "            \n",
    "            # obtaining bouning boxes for objects contours\n",
    "            OFFSET = 3  # offset obtained after dilation\n",
    "            SHADOW = 8 # average thickness of a shadow to remove it within box\n",
    "            boxes  = [] # boxes for particular frame\n",
    "            for cont in contours:\n",
    "                \n",
    "                # obtaining box coordinates\n",
    "                x, y, w, h = cv2.boundingRect(cont)\n",
    "                \n",
    "                # normalizing them\n",
    "                x += OFFSET // 2\n",
    "                w -= OFFSET\n",
    "                h -= SHADOW\n",
    "                y -= OFFSET\n",
    "                \n",
    "                # appending the to the boxes holding structure\n",
    "                boxes.append((x, y, x + w, y + h))\n",
    "                \n",
    "            # adding boxes to the overall boxes quantity\n",
    "            self.boxes.append(boxes)\n",
    "            \n",
    "            # plotting the process of obtaining the car contours for debugging\n",
    "            if debug: show([gauss, thresh, dilated, current_frame]); break\n",
    "                \n",
    "        # increasing the precision of detection by correcting the bounding boxes\n",
    "        self.merge_bounding_boxes()\n",
    "                \n",
    "    def merge_bounding_boxes(self):\n",
    "        '''\n",
    "        Correct the output of contour detection and merge bounding boxes of the same object\n",
    "        into one bounding box\n",
    "        '''\n",
    "        \n",
    "        def boxes_are_merged(boxes, h_thr, w_thr):\n",
    "            '''\n",
    "            Given a list of boxes checks if some of them belong the same object\n",
    "            '''\n",
    "            \n",
    "            # going through each pair of boxes\n",
    "            for i in range(len(boxes) - 1):\n",
    "                for j in range(i + 1, len(boxes)):\n",
    "                    \n",
    "                    # defining the centers of wo bounding boxes\n",
    "                    center1 = ((boxes[i][0] + boxes[i][2]) // 2, (boxes[i][1] + boxes[i][3]) // 2)\n",
    "                    center2 = ((boxes[j][0] + boxes[j][2]) // 2, (boxes[j][1] + boxes[j][3]) // 2)\n",
    "                    \n",
    "                    # checking their similarity w.r.t. to their centers\n",
    "                    if abs(center1[0] - center2[0]) <= w_thr and abs(center1[1] - center2[1]) <= h_thr:\n",
    "                        return False\n",
    "\n",
    "            # returning true is there are no pairs to merge\n",
    "            return True\n",
    "        \n",
    "        def merged_boxes(boxes, h_thr, w_thr):\n",
    "            '''\n",
    "            Merging the first pair of boxes which it sees\n",
    "            '''\n",
    "            \n",
    "            # set of indices which are merged\n",
    "            victims = set()\n",
    "            \n",
    "            # going through each pair of boxes\n",
    "            for i in range(len(boxes) - 1):\n",
    "                for j in range(i + 1, len(boxes)):\n",
    "                    \n",
    "                    # defining the centers of wo bounding boxes\n",
    "                    center1 = ((boxes[i][0] + boxes[i][2]) // 2, (boxes[i][1] + boxes[i][3]) // 2)\n",
    "                    center2 = ((boxes[j][0] + boxes[j][2]) // 2, (boxes[j][1] + boxes[j][3]) // 2)\n",
    "                    \n",
    "                    # if similar then we merge\n",
    "                    if abs(center1[0] - center2[0]) <= w_thr and abs(center1[1] - center2[1]) <= h_thr:\n",
    "                        \n",
    "                        # defining a box which will go away\n",
    "                        victims.add(i)\n",
    "                        \n",
    "                        # populating a master box \n",
    "                        boxes[j] = (\n",
    "                            min(boxes[i][0], boxes[j][0]),\n",
    "                            min(boxes[i][1], boxes[j][1]),\n",
    "                            max(boxes[i][2], boxes[j][2]),\n",
    "                            max(boxes[i][3], boxes[j][3])\n",
    "                        )\n",
    "                        \n",
    "            # filtering out the victim boxes because they got merged      \n",
    "            return [box for i, box in enumerate(boxes) if i not in victims]\n",
    "        \n",
    "        # defining thresholds for searching the similarity between bounding boxes\n",
    "        HEIGHT_THRESH = 10\n",
    "        WIDTH_THRESH  = 50\n",
    "        \n",
    "        # going through each set of boxes\n",
    "        for i in range(len(self.boxes)):\n",
    "            \n",
    "            # merging boxes until we merge every pair with each other\n",
    "            while not boxes_are_merged(self.boxes[i], HEIGHT_THRESH, WIDTH_THRESH):\n",
    "                self.boxes[i] = merged_boxes(self.boxes[i], HEIGHT_THRESH, WIDTH_THRESH) \n",
    "                \n",
    "    def compute_trails(self):\n",
    "        '''\n",
    "        Transforming simple bounding boxes and moving objects\n",
    "        with trail color and trail length\n",
    "        '''\n",
    "        \n",
    "        # structure which will hold the moving objects\n",
    "        self.objects = []\n",
    "        \n",
    "        # initializing the 2nd frame objects using the first pack of boxes\n",
    "        self.objects.append([MovingObject(box) for box in self.boxes[0]])\n",
    "        \n",
    "        # going through each set of boxes\n",
    "        for i in range(1, len(self.boxes)):\n",
    "            \n",
    "            # initializing objects of current and previous frame\n",
    "            prev_obj = self.objects[-1]\n",
    "            cur_obj  = [MovingObject(box) for box in self.boxes[i]]\n",
    "            \n",
    "            # finding the similarities between objects on current and previous frame\n",
    "            similarities = [[None for j in range(len(prev_obj))] for k in range(len(cur_obj))]\n",
    "            for j in range(len(cur_obj)):\n",
    "                for k in range(len(prev_obj)):\n",
    "                    \n",
    "                    # calculating the Intersection over Union metric for each pair of objects\n",
    "                    similarities[j][k] = cur_obj[j].iou(prev_obj[k])\n",
    "                    \n",
    "            # finding object which maximizes IoU similarity\n",
    "            for j, row in enumerate(similarities):\n",
    "                \n",
    "                # getting the most fitting result\n",
    "                max_sim = max(row)\n",
    "                \n",
    "                # if there exists the same object on the next frame\n",
    "                # we continue the trail and reassign the coordinates of bounding box\n",
    "                if max_sim > 0.1:\n",
    "                    \n",
    "                    # getting the position of object on previous frame\n",
    "                    prev_obj_ind = row.index(max_sim)\n",
    "                    \n",
    "                    # updating the information about trails and color\n",
    "                    cur_obj[j].color = prev_obj[prev_obj_ind].color\n",
    "                    cur_obj[j].trail = prev_obj[prev_obj_ind].trail[:]\n",
    "                    \n",
    "                    # appending another point to the trail\n",
    "                    cur_obj[j].draw_point()\n",
    "            \n",
    "            # appending the objects with updated info\n",
    "            self.objects.append(cur_obj)\n",
    "\n",
    "    def detect_and_record(self, path):\n",
    "        '''\n",
    "        Detect moving objects on a processed video and produce and output\n",
    "        in the form of video with bounding boxes\n",
    "        '''\n",
    "        \n",
    "        # populating bounding boxes \n",
    "        self.detect_bounding_boxes()\n",
    "        \n",
    "        # computing the trails for each moving object\n",
    "        self.compute_trails()\n",
    "        \n",
    "        # drawing them on every available image frame\n",
    "        for frame, objects in zip(self.frames[1:], self.objects):\n",
    "            \n",
    "            # going through each object in defined boxes and drawing info about it\n",
    "            for obj in objects:\n",
    "                \n",
    "                # drawing the last 'limit' points of the trail\n",
    "                for x, y in obj.trail[-min(obj.limit, len(obj.trail)):]:\n",
    "                    cv2.circle(frame, (x, y), radius = 2, color = obj.color, thickness = -1)\n",
    "                \n",
    "                # drawing the bounding box\n",
    "                cv2.rectangle(frame,\n",
    "                              (obj.coords[0], obj.coords[1]),\n",
    "                              (obj.coords[2], obj.coords[3]),\n",
    "                              (0, 0, 255), 2)\n",
    "        \n",
    "        # getting the shape of the frame \n",
    "        h, w, _ = self.frames[0].shape\n",
    "        \n",
    "        # initializing the writing to video engine\n",
    "        video = cv2.VideoWriter('detected.avi', cv2.VideoWriter_fourcc(*'DIVX'), 60, (w, h))\n",
    "        \n",
    "        # going through each obtained image and adding it to the video\n",
    "        for frame in self.frames:\n",
    "            video.write(frame)\n",
    "        \n",
    "        # releasing the video and finishing writing\n",
    "        video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17db472b-95d2-4830-ad19-5e3b1b537a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect0r = MyObjectDetector('cars.mp4')\n",
    "detect0r.detect_and_record('detected.avi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
